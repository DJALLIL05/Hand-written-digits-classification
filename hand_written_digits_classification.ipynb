{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hand written digits classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNSbMfJU/jd3/YgFTTdilNA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DJALLIL05/Predicting-Customer-Behavior/blob/main/hand_written_digits_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXue0yrDfv7t"
      },
      "source": [
        "## importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwz6ho4tExSg"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOp9j5_tf4kC"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoJjEUgmFEA2",
        "outputId": "4eac371a-2338-4db2-c2bc-8fdce56b65aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "# loading the mnist dataset\n",
        "mnist_dataset, mnist_info = tfd.load(name = 'mnist', with_info=True, as_supervised=True)\n",
        "print('description of the mnist dataset:\\n', mnist_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "description of the mnist dataset:\n",
            " tfds.core.DatasetInfo(\n",
            "    name='mnist',\n",
            "    version=3.0.0,\n",
            "    description='The MNIST database of handwritten digits.',\n",
            "    homepage='http://yann.lecun.com/exdb/mnist/',\n",
            "    features=FeaturesDict({\n",
            "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
            "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
            "    }),\n",
            "    total_num_examples=70000,\n",
            "    splits={\n",
            "        'test': 10000,\n",
            "        'train': 60000,\n",
            "    },\n",
            "    supervised_keys=('image', 'label'),\n",
            "    citation=\"\"\"@article{lecun2010mnist,\n",
            "      title={MNIST handwritten digit database},\n",
            "      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n",
            "      journal={ATT Labs [Online]. Available: http://yann. lecun. com/exdb/mnist},\n",
            "      volume={2},\n",
            "      year={2010}\n",
            "    }\"\"\",\n",
            "    redistribution_info=,\n",
            ")\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2jaVibCf_hU"
      },
      "source": [
        "## Splitting the data into training, validation and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xABQsQtFqLV"
      },
      "source": [
        "# splitting the data into training and test datasets\n",
        "mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test']\n",
        "# choosing 10% of the training data as validation data\n",
        "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples\n",
        "num_validation_samples = tf.cast(num_validation_samples, tf.int64)\n",
        "\n",
        "num_test_samples = mnist_info.splits['test'].num_examples\n",
        "num_test_samples = tf.cast(num_test_samples, tf.int64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZADT3o-gqSx"
      },
      "source": [
        "## Scaling the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2kH2PUKJoSJ"
      },
      "source": [
        "def scale(image, label):\n",
        "  \"\"\"scale: function to scale the data\n",
        "  args:\n",
        "  image: a tensor of shape (28,28,1)\n",
        "  label: takes values from 0 to 9\n",
        "  retrun:\n",
        "  image: flatten the tensor into a vector\n",
        "  label: the same as the input label\"\"\"\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image /= 225.\n",
        "  return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU15clGJKD_m"
      },
      "source": [
        "# scaling the training and testing datasets\n",
        "scaled_train_and_validation_data = mnist_train.map(scale)\n",
        "scaled_test_data = mnist_test.map(scale)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1BvhiaGguSY"
      },
      "source": [
        "## Shuffling the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBaX4QCQMwVo"
      },
      "source": [
        "# shuffling the training, validatio and testing datasets\n",
        "BUFFER_SIZE = 10000\n",
        "shuffled_train_and_validation_data = scaled_train_and_validation_data.shuffle(BUFFER_SIZE)\n",
        "validation_data =  shuffled_train_and_validation_data.take(num_validation_samples)\n",
        "train_data = shuffled_train_and_validation_data.skip(num_validation_samples)\n",
        "test_data = scaled_test_data.shuffle(100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75Oy7OLRg0pw"
      },
      "source": [
        "## Setting batch sizes for train, validation and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "II1v17F7QkU5"
      },
      "source": [
        "# setting the batch size for the train, validation and test datasets\n",
        "BATCH_SIZE = 100\n",
        "train_data = train_data.batch(BATCH_SIZE)\n",
        "validation_data = validation_data.batch(num_validation_samples)\n",
        "test_data = test_data.batch(num_test_samples)\n",
        "validation_inputs, validation_targets = next(iter(validation_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZbRXKA1g84D"
      },
      "source": [
        "## Creating the neural network model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgV5Ytv_Sk0u"
      },
      "source": [
        "# creating the model\n",
        "input_size = 784\n",
        "output_size = 10\n",
        "hidden_layer_size = 50\n",
        "model = tf.keras.Sequential([tf.keras.layers.Flatten(input_shape = (28, 28, 1)),\n",
        "                            tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
        "                            tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
        "                            tf.keras.layers.Dense(output_size, activation = 'softmax')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATiNrtKOhDT5"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuqVDI6vW03c"
      },
      "source": [
        "# setting the optimization algorithm and the loss function\n",
        "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NN5EsfNXJKH",
        "outputId": "76959aed-8c05-4f8b-9f5a-81cd8d894992",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# training the model\n",
        "NUM_EPOCHS = 5\n",
        "model.fit(train_data, epochs = NUM_EPOCHS, validation_data = (validation_inputs, validation_targets), verbose = 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "540/540 - 6s - loss: 0.4045 - accuracy: 0.8848 - val_loss: 0.2087 - val_accuracy: 0.9410\n",
            "Epoch 2/5\n",
            "540/540 - 6s - loss: 0.1795 - accuracy: 0.9480 - val_loss: 0.1531 - val_accuracy: 0.9545\n",
            "Epoch 3/5\n",
            "540/540 - 7s - loss: 0.1384 - accuracy: 0.9585 - val_loss: 0.1265 - val_accuracy: 0.9620\n",
            "Epoch 4/5\n",
            "540/540 - 6s - loss: 0.1163 - accuracy: 0.9652 - val_loss: 0.1132 - val_accuracy: 0.9642\n",
            "Epoch 5/5\n",
            "540/540 - 7s - loss: 0.0976 - accuracy: 0.9702 - val_loss: 0.0923 - val_accuracy: 0.9722\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f78861bb668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imN0wn7ghHoU"
      },
      "source": [
        "## Evaluating model performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGkAMwjfYdEQ",
        "outputId": "6d39ab90-17dd-4f5a-e2c6-6e44ffb31fb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# testing the model\n",
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "print('Test loss: {0: .2f}. Test accuracy: {1: 2f}%'.format(test_loss, test_accuracy * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1027 - accuracy: 0.9689\n",
            "Test loss:  0.10. Test accuracy:  96.890002%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcHw5d2CZxqk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}